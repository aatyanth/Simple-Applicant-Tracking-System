{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install pdfminer.six\n",
        "! pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi3xzNi5LkI8",
        "outputId": "d2ee7e87-a9a2-4011-a9b1-d30f9ac9927f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (20231228)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For converting pdf to text\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "#For NLP preprocessing\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#For calculating keywords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#For final score assigning\n",
        "import numpy as np\n",
        "from scipy.stats import percentileofscore\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCrgq37tKWQL",
        "outputId": "68bfffaa-099b-4022-8dbf-a329d3d0e040"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_uLF8zd-GPjd"
      },
      "outputs": [],
      "source": [
        "# Function converts the pdf files to text and stores it in a string\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "  return extract_text(pdf_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This function uses the NLP module nltk to remove stopwords\n",
        "# and lemmatize words in the text from above\n",
        "def preprocess(extracted_text):\n",
        "\n",
        "  nltk.download('stopwords')\n",
        "  nltk.download('punkt')\n",
        "\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "  tokens = word_tokenize(extracted_text)\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "  lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "\n",
        "  filtered_text = ' '.join(lemmatized_tokens)\n",
        "\n",
        "  return filtered_text\n"
      ],
      "metadata": {
        "id": "eY59-41_K1s6"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function uses the TFIDF algorithm to get the keywords from the\n",
        "# preprocessed text\n",
        "def get_keywords(preprocessed_text):\n",
        "  tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "  tfidf_matrix = tfidf_vectorizer.fit_transform([preprocessed_text])\n",
        "\n",
        "  feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "  top_keywords = [feature_names[id] for id in tfidf_matrix[0].indices]\n",
        "\n",
        "  return top_keywords\n"
      ],
      "metadata": {
        "id": "q1FZTUAVZneP"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function uses a keyword matching algorithm to track how well\n",
        "# the keywords from my resume match the keywords from the job description\n",
        "def keyword_matching(description_keywords, resume_keywords):\n",
        "  match_count = sum(1 for keyword in resume_keywords if keyword in description_keywords)\n",
        "  match_percent = match_count/len(description_keywords)\n",
        "\n",
        "  return match_percent * 100"
      ],
      "metadata": {
        "id": "chcgx9ZtetJ-"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function assigns a final score from 0-5 based on the percentile score\n",
        "# of my resume compared to other resumes' match percents from my algorithm\n",
        "def assign_score(percent_array):\n",
        "  my_score = percent_array[0]\n",
        "\n",
        "  percentile_rank = percentileofscore(percent_array, my_score)\n",
        "  percentile_thresholds = [10, 25, 50, 75, 90]\n",
        "  score_scale = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "  for i, threshold in enumerate(percentile_thresholds):\n",
        "    if percentile_rank <= threshold:\n",
        "        my_final_score = score_scale[i+1]\n",
        "        break\n",
        "  else:\n",
        "    my_final_score = score_scale[-1]\n",
        "\n",
        "  print(\"My Final Score:\", my_final_score)"
      ],
      "metadata": {
        "id": "oD6bWsMjh3CW"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#These lines take my resume pdf and run it through 3 functions defined above\n",
        "path_for_resume = '/content/Aatyanth_Resume_VF.pdf'\n",
        "extracted_text_from_resume = extract_text_from_pdf(path_for_resume)\n",
        "prepreoccessed_resume = preprocess(extracted_text_from_resume)\n",
        "keywords_resume = get_keywords(prepreoccessed_resume)\n",
        "\n",
        "\n",
        "# These lines take the job description pdf and run it through 3 functions\n",
        "# defined above\n",
        "path_for_description = '/content/Find_the_Right_Job_description.pdf'\n",
        "extracted_text_from_description = extract_text_from_pdf(path_for_description)\n",
        "preprocessed_description = preprocess(extracted_text_from_description)\n",
        "keywords_description = get_keywords(preprocessed_description)\n",
        "\n",
        "\n",
        "# This line prints the keyword match percentage between my resume and the job\n",
        "# description\n",
        "print ('THIS IS MY MATCH PERCENTAGE: ')\n",
        "print(keyword_matching(keywords_description, keywords_resume))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OEzOsPJMoSv",
        "outputId": "6b5d7c60-f719-4c38-dbfc-8d6631215b43"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THIS IS MY MATCH PERCENTAGE: \n",
            "15.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is for creating a standardized scoring system based on my code\n",
        "# The sample resumes are all aquired online\n",
        "\n",
        "# This line preprocesses and gets the keywords for sample resume 1\n",
        "s1_path = '/content/Sample1.pdf'\n",
        "s1_extracted_text_from_resume = extract_text_from_pdf(s1_path)\n",
        "s1_prepreoccessed_resume = preprocess(s1_extracted_text_from_resume)\n",
        "s1_keywords_resume = get_keywords(s1_prepreoccessed_resume)\n",
        "\n",
        "# This line preprocesses and gets the keywords for sample resume 2\n",
        "s2_path = '/content/sample2.pdf'\n",
        "s2_extracted_text_from_resume = extract_text_from_pdf(s2_path)\n",
        "s2_prepreoccessed_resume = preprocess(s2_extracted_text_from_resume)\n",
        "s2_keywords_resume = get_keywords(s2_prepreoccessed_resume)\n",
        "\n",
        "# This line preprocesses and gets the keywords for sample resume 3\n",
        "s3_path = '/content/sample3.pdf'\n",
        "s3_extracted_text_from_resume = extract_text_from_pdf(s3_path)\n",
        "s3_prepreoccessed_resume = preprocess(s3_extracted_text_from_resume)\n",
        "s3_keywords_resume = get_keywords(s3_prepreoccessed_resume)\n",
        "\n",
        "# This line preprocesses and gets the keywords for sample resume 4\n",
        "s4_path = '/content/sample4.pdf'\n",
        "s4_extracted_text_from_resume = extract_text_from_pdf(s4_path)\n",
        "s4_prepreoccessed_resume = preprocess(s4_extracted_text_from_resume)\n",
        "s4_keywords_resume = get_keywords(s4_prepreoccessed_resume)\n",
        "\n",
        "# This line creates an array containing the keyword match percentage for each\n",
        "# sample resume 1-4\n",
        "s_perctange_match= [keyword_matching(keywords_description, s1_keywords_resume), keyword_matching(keywords_description, s2_keywords_resume),\n",
        "                    keyword_matching(keywords_description, s3_keywords_resume), keyword_matching(keywords_description, s4_keywords_resume)]\n",
        "\n",
        "# This line creates an array containg the keyword match percentage for my\n",
        "# resume and all the sample resumes 1-4\n",
        "assigning_score = [keyword_matching(keywords_description, keywords_resume),keyword_matching(keywords_description, s1_keywords_resume),\n",
        "                   keyword_matching(keywords_description, s2_keywords_resume), keyword_matching(keywords_description, s3_keywords_resume),\n",
        "                   keyword_matching(keywords_description, s4_keywords_resume)]\n",
        "\n",
        "# This line sends the assigning_score array as an input to the statistical\n",
        "# function used to calculate the final score for how well my resume matches\n",
        "# the job description\n",
        "assign_score(assigning_score)\n",
        "\n",
        "### MY FINAL SCORE IS A 4 ###"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGamAVCcmBdW",
        "outputId": "eef18f64-5a10-4a1f-fd4c-81f0c55e1d58"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My Final Score: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}